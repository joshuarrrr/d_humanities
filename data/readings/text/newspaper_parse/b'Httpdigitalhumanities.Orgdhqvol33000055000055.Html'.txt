Technological Progressivism

The narratives that surround technology tend, understandably, to be progressive. Mooreâs law, which states that the complexity and hence the processing power of computer chips is doubling every couple of years, and Kryderâs law, which says something similar about disk capacity, have visible and in some cases stunning illustrations in the world around us. We see evidence in products such as palmtop devices that have thousands of times the computing power and storage capacity of ENIAC, the first stored-program electronic computer; personal disk storage is now purchasable almost by the terabyte, and processor speed is now measured by the gigahertz; both of these statements will have dated by the time this article is published. We also see the effects of these developments in processes whose increasing speed produces subtle luxuries that creep into our lives, almost without our taking particular notice: for example, color screens for computers, three-dimensional icons, the clever animation behaviors that are as ubiquitous (and as useful) as small plastic childrenâs toys. Or, more substantively: the fact that you can now store and edit digital video footage on your laptop, or view streaming movies on a device you can put in your pocket. These kinds of change produce easy metrics for success and a correspondingly easy sense of progress.

Digital humanities scholarship to a large degree shares this sense of progress. We see, first of all, simple infrastructural developments that change the social location of computers and bring them into our sphere of activity. The ubiquity of computing resources means that itâs no longer remarkable for humanities scholars to work with computers: one doesnât have to get a special account from Central Computing or explain why one needs it; itâs not considered quaint or cute or bizarre. Certain efficiencies and conveniences are now commonplace; it has become expected that things scholars want to read or learn will be more or less easily available from anywhere, at any hour, electronically. And there are indirect effects as well: all of these changes produce the conditions for consumer-level products like electronic book readers, hand-held browsing devices, social software like Flickr and YouTube. These products provide extended horizons of usage, and produce a generation of students (and eventually future scholars) for whom computers mean something completely different: for whom they are not a specialized tool but part of the tissue of the world.

The effects of these developments are all around us in the emerging shape of digital scholarly tools and research materials. At a basic level, the increased power of modern computers is almost literally what makes it possible to use them effectively for humanities research. In early computer systems, scarcity of storage space dictated extremely frugal methods of representing characters: because it only uses 7 bits of information to represent each character, ASCII can represent only 128 characters, of which only 95 are actually printable characters. This limited the effective alphabet to upper- and lower-case roman letters, Arabic numerals, and common punctuation marks, with no accented characters or characters from non-roman alphabets. The advent of Unicode in the 1990s is a direct outcome of the increase in storage space, allowing the representation of nearly all human writing systems and freeing digital scholarship on texts from early artificial limitations.

This same comparative abundance of space has also opened up the whole domain of image processing, giving us another information vector to use for research, leading to work in which the graphical meaning of text can be explored alongside its linguistic meaning. and allowing us also to explore the interpenetration of image-based and text-based approaches. To appropriate a term Jerome McGann suggested in his opening keynote to the conference at which this paper was originally presented, there is a dialectical process opening up here as well: the mutual pressure of image and text, of alphabetic and figural modes of representing meaning, is now blossoming into an extremely lively field of study.

The rhetoric of abundance which has characterized descriptions of digital resource development for the past decade or more has suggested several significant shifts of emphasis in how we think about the creation of collections and of canons. It is now easier, in some contexts, to digitize an entire library collection than to pick through and choose what should be included and what should not: in other words, storage is cheaper than decision-making. The result is that the rare, the lesser-known, the overlooked, the neglected, and the downright excluded are now likely to make their way into digital library collections, even if only by accident. In addition, the design of digital collections now frequently emphasizes precisely the recovery of what has been lost, the exposure of what has been inaccessible. Projects like the Women Writers Project, or Early English Books Online, or any one of countless digital projects now under way at universities across the country, focus on providing access to materials that would otherwise be invisible to researchers. This access proceeds on two fronts: first, by digitizing them so that they can be read without visiting the specific archive where they are held, but also, more importantly, by aggregating them and making them discoverable, by heaping them up into noticeable piles. The result is that minority literatures, non-canonical literary works, and the records of what goes on in (what appeared earlier to be) the odd corners of the universe are all given a new kind of prominence and parity with their more illustrious and familiar cousins.

Invisibly, under the hood (so to speak), increased speed and computing power has also given us tools that finally propel us over the threshold of possibility: humanities novices are becoming able to participate meaningfully in what would formerly have appeared to be impossibly technical projects. Examples include tools for XML text encoding that are good enough, and fast enough, that anyone can learn to use them within ten minutes; or, similarly, tools for image manipulation that put real power in a noviceâs hands. Even improvements in things like compression algorithms, as Morris Eaves observes in his contribution to this issue, have a huge impact on the accuracy and effectiveness of digital image representation.

...one of the many things you can do with computers is something that I would call humanities computing, in which the computer is used as tool for modeling humanities data and our understanding of it, and that activity is entirely distinct from using the computer when it models the typewriter, or the telephone, or the phonograph, or any of the many other things it can be. Â [Unsworth 2002] Unlike its comparatively recent ability to model the telephone or the phonograph, the computerâs role as a tool for modeling humanities data is of long standing â arguably extending back to Father Roberto Busaâs 1945 Index Thomisticus and certainly including early tools and methods including concordancing, text analysis, and text markup languages. Although our ability to work with these models has without doubt been made easier by the advent of faster, more seamless tools, the complexity and interest of the models themselves has been affected little if at all. We have only to consider as an example Willard McCartyâs remarkable project of modeling mutability in his Analytical Onomasticon to the Metamorphoses of Ovid , a project of great complexity and nuance which was undertaken almost entirely through markup and without the aid of any specialized tools for model construction, visualization, or data manipulation. The nature of the models being created in the digital humanities may be changing with time, but not as a function of speed or power, but rather as a result of changes in emphasis or theoretical concern. But despite the fact that these are tangible improvements, there is also an important sense in which their progressive momentum is not, ultimately, what is characteristic of the digital humanities as a field. John Unsworth, in an article entitled "What is Humanities Computing and What is Not?" makes a point of noting the difference between using a computer for any of its many practical purposes, and using the computer as a scholarly tool:Unlike its comparatively recent ability to model the telephone or the phonograph, the computerâs role as a tool for modeling humanities data is of long standing â arguably extending back to Father Roberto Busaâs 1945and certainly including early tools and methods including concordancing, text analysis, and text markup languages. Although our ability to work with these models has without doubt been made easier by the advent of faster, more seamless tools, the complexity and interest of the models themselves has been affected little if at all. We have only to consider as an example Willard McCartyâs remarkable project of modeling mutability in his, a project of great complexity and nuance which was undertaken almost entirely through markup and without the aid of any specialized tools for model construction, visualization, or data manipulation. The nature of the models being created in the digital humanities may be changing with time, but not as a function of speed or power, but rather as a result of changes in emphasis or theoretical concern.

In this respect, the digital humanities domain reflects the non-progressiveness of the humanities disciplines more generally, and also reveals what may be a fundamental tension at its heart. If the rhetoric at the heart of the "digital" side of "digital humanities" is strongly informed by a narrative of technological progress, the "humanities" side has equally strong roots in a humanities sensibility which both resists a cumulative idea of progress (one new thing building on another) and yearns for a progressive agenda (doing better all the time). The theoretical and methodological shifts that constitute disciplinary change in the humanities, when viewed in retrospect, do not appear clearly progressive in the way that sequences of scientific discoveries do, though they do appear developmental: they are an ongoing attempt to understand human culture, from the changing perspective of the culture itself. But the resilience of fundamental habits and assumptions concerning literary value, scholarly method, and academic standards suggests that the humanities are in fact governed by a self-healing ideology that persists comparatively unchanged.

In charting the intellectual aspirations of the digital humanities, it is tempting to elide the difference between this sense of ongoing debate and the gains in size and speed that come from the technological domain. But the intervention made by digital technology when it truly engages with humanities disciplines is something apart from both the simple progressivism of technology and the canonical resilience of the traditional humanities. In the same article I quoted from earlier, John Unsworth characterized humanities computing as follows:

[h]umanities computing is a practice of representation, a form of modeling or [...] mimicry. It is[...] a way of reasoning and a set of ontological commitments, and its representational practice is shaped by the need for efficient computation on the one hand, and for human communication on the other. Â [Unsworth 2002]

In other words, it is neither about discovery of new knowledge nor about the solidity of what is already known: it is rather about modeling that knowledge and even in some cases about modeling the modeling process. It is an inquiry into how we know things and how we present them to ourselves for study, realized through a variety of tools which make the consequences of that inquiry palpable. This is why, when humanities practitioners learn a technology like text encoding, they feel both a frisson of recognition â of a process that is familiar, that expresses familiar ideas â and also the shock of the new: the requirement that one distance oneself from oneâs own representational strategies and turn them about in oneâs hands like a complex and alien bauble. As Unsworth puts it further along,

Humanities computing, as a practice of knowledge representation, grapples with this realization that its representations are surrogates in a very self-conscious way, more self-conscious, I would say, than we generally are in the humanities when we "represent" the objects of our attention in essays, books, and lectures. Â [Unsworth 2002]

Representational technologies like XML, or databases, or digital visualization tools appear to stand apart from the humanities research activities they support, even while they encapsulate and seek to do justice to the assumptions and methods of those activities. Humanities scholarship has historically understood this separateness as indicating an ancillary role â that of the handmaiden, the good servant/poor master â in which humanities insight masters and subsumes what these technologies can offer. Technology implements what humanities insight projects as a research trajectory. But in fact the relationship is potentially more complex: by expressing "human communication" in the formal language needed for what Unsworth calls "efficient computation," these representational technologies attempt to restate those methods in terms which are not identical to, not embedded in the humanities discourse. They effect a distancing, a translation which, like any translation or transmediation, provides a view into (and requires an understanding of) the deep discursive structures of the original expression.

Unsworth is careful to observe that not all digital humanities activities â in fact, very few â really constitute this kind of intervention, or count as "humanities computing" according to his strict definition. The act of publishing digital content, of making an uncritical digital facsimile of a physical artifact, does not produce this effect of translation or the resulting potential for insight. I would argue that we can recognize humanities computing in his sense of the term, precisely by a kind of productive unease that results from the encounter and from its product. This unease registers for the humanities scholar as a sense of friction between familiar mental habits and the affordances of the tool, but it is ideally a provocative friction, an irritation that prompts further thought and engagement. In the nature of things â systems and people being imperfect â it might produce a suspicion that the tool in question is maladapted for use in humanities research. In some cases that may be true, and in some cases that may be a self-defensive response which deserves further probing. But where that sense of friction is absent â where a digital object sits blandly and unobjectionably before us, putting up no resistance and posing no questions for us â humanities computing, in the meaningful sense, is also absent. Humanists may learn from the content of such objects, treated as research materials, as they always have. These objects will serve as more or less effective surrogates for their physical originals and may produce efficiencies of access and other practical benefits of one sort or another. But they have no contribution to make to humanities scholarship: they make no intervention, they leave no intellectual mark.